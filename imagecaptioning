import tensorflow as tf
from tensorflow.keras.layers import Conv2D, Flatten, Dense

# Define the CNN Encoder
class CNNEncoder(tf.keras.Model):
    def __init__(self):
        super(CNNEncoder, self).__init__()
        self.conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')
        self.conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')
        self.flatten = Flatten()
        self.fc = Dense(256, activation='relu')

    def call(self, inputs):
        x = self.conv1(inputs)
        x = self.conv2(x)
        x = self.flatten(x)
        x = self.fc(x)
        return x

# Define the Decoder
class RNNDecoder(tf.keras.Model):
    def __init__(self, vocab_size, embedding_dim, units):
        super(RNNDecoder, self).__init__()
        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)
        self.lstm = tf.keras.layers.LSTM(units, return_sequences=True, return_state=True)
        self.fc = tf.keras.layers.Dense(vocab_size)

    def call(self, inputs, initial_state):
        x = self.embedding(inputs)
        x, state_h, state_c = self.lstm(x, initial_state=initial_state)
        x = self.fc(x)
        return x, state_h, state_c

# Create instances of Encoder and Decoder
encoder = CNNEncoder()
decoder = RNNDecoder(vocab_size, embedding_dim, units)

# Sample input image
sample_image = tf.random.normal((batch_size, img_height, img_width, img_channels))

# Pass input image through the Encoder
encoded_features = encoder(sample_image)

# Pass encoded features to Decoder's initial state
initial_state = [encoded_features, encoded_features] 
decoder_output, _, _ = decoder(target_sequence, initial_state)
